
Rag agent execution result is :
上周，我在美国国会就人工智能及其监管问题发表了演讲，出席此次活动的有立法和商界领袖。我对开源社区在抵制可能抑制创新的法规方面取得的进展感到鼓舞。但反对开源的人不断改变他们的论点，最新的担忧集中在开源对国家安全的影响上。我希望我们都能继续保护开源！

根据我与立法者的对话，我对美国联邦政府在更现实地理解人工智能风险方面取得的进展感到鼓舞。需要明确的是，确实需要设立一些规范。但这些规范应针对具体的人工智能应用，而不是通用的人工智能技术。

尽管如此，正如我之前所写，一些公司热衷于限制开源，可能是为了保护他们在专有模型上的巨额投资，并阻止竞争对手。观察他们的论点随时间变化非常有趣。

例如，大约12个月前，人工智能安全中心的“关于人工智能风险的声明”警告说，人工智能可能导致人类灭绝，并引发了对人工智能接管的恐惧。这令华盛顿的领导人感到震惊。但许多人工智能领域的专家指出，这种反乌托邦的科幻场景在现实中几乎没有依据。大约六个月后，当我在美国参议院的人工智能洞察论坛上作证时，立法者已经不再过多担心人工智能接管的问题。

然后，反对开源的人调整了策略。他们将主要论点转向了人工智能可能帮助制造生物武器的风险。不久之后，OpenAI和RAND的研究显示，当前的人工智能并未显著增加不法分子制造生物武器的能力。对人工智能可能赋能生物武器的恐惧已经减弱。当然，无论是否涉及人工智能，不良行为者使用生物武器的可能性仍然是国际社会高度关注的问题。最新的反对开源AI的理由转向了国家安全问题。AI在经济竞争和战争中都有重要作用，开源的反对者认为美国应确保其对手无法获取最新的基础模型。虽然我不希望专制政府利用AI，尤其是用于发动不义之战，但木已成舟，如果民主国家限制访问，专制国家将会填补这一空白。当有一天某个地方的孩子向AI系统询问关于民主、自由媒体的作用或独立司法机构在维护法治中的职能时，我希望AI能够体现民主价值观，而不是偏向专制领导者的利益，如忽视人权。

我从华盛顿回来后对我们的进展感到乐观。一年前，立法者似乎将80%的时间用于讨论AI的监管，而只有20%的时间用于讨论投资创新。我很高兴看到这一比例发生了逆转，现在更多地讨论投资创新。

除了美国联邦政府外，全球还有许多司法管辖区。不幸的是，支持扼杀AI发展的监管论调仍在不断增加。然而，通过我在华盛顿及其他国家首都的访问，我发现与监管者对话确实有影响。如果你有机会与任何级别的监管者交谈，我希望你能尽自己所能帮助政府更好地理解AI。